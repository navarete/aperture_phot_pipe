{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "# based on https://notebook.community/Python4AstronomersAndParticlePhysicists/PythonWorkshop-ICE/notebooks/10_03_Astronomy_PhotUtils\n",
    "%matplotlib inline\n",
    "from astropy              import units as u\n",
    "from astropy              import wcs\n",
    "from astropy.io           import fits\n",
    "from astropy.coordinates  import SkyCoord\n",
    "from astropy.modeling     import models, fitting\n",
    "from astropy.stats        import sigma_clipped_stats, SigmaClip\n",
    "\n",
    "from photutils            import DAOStarFinder, CircularAperture, aperture_photometry, CircularAnnulus\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "from photutils.utils      import calc_total_error\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "# set default matplotlib parameters\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 13\n",
    "\n",
    "# let's make a function that makes our code cleaner for visualization:\n",
    "from astropy.visualization import ZScaleInterval\n",
    "def display(data, cb_title=''):\n",
    "    norm = ZScaleInterval()\n",
    "    vmin, vmax = norm.get_limits(data)\n",
    "    plt.imshow(data, vmin=vmin, vmax=vmax, interpolation='none', origin='lower')\n",
    "    plt.colorbar(label=cb_title)\n",
    "\n",
    "def get_bkg(img, sigma=3.0, maxiters=5):\n",
    "    \"\"\" \n",
    "        Estimate background  statistics (median and standard deviation) \n",
    "        of a fits image after applying a sigma-clipping routine\n",
    "        \n",
    "        Parameters:\n",
    "           img (numpy.ndarray): input image\n",
    "           sigma (float, optional):  number of standard deviations to use for both the lower and upper clipping limit (default=3.0)\n",
    "           maxiters (int, optional): maximum number of sigma-clipping iterations to perform (default=5)\n",
    "           \n",
    "        Returns:\n",
    "           median, std (float): the median, and standard deviation of the sigma-clipped data\n",
    "    \"\"\"\n",
    "    mean, median, std = sigma_clipped_stats(img, sigma=sigma, maxiters=maxiters)    \n",
    "    return median, std\n",
    "\n",
    "def get_pixelscale(img_wcs, pixscale=None):\n",
    "    \"\"\" \n",
    "        Return the pixel scale of a fits image\n",
    "        \n",
    "        Parameters:\n",
    "           img_wcs (astropy.wcs.wcs.WCS): input WCS from the fits file\n",
    "           pixscale (float, optional): if pixel scale not found, use the provided value instead (in arcseconds)\n",
    "           \n",
    "        Returns:\n",
    "           pixscale (float): the pixel scale of the image (in arcseconds)\n",
    "    \"\"\"\n",
    "    if pixscale is None:\n",
    "        pixelscale = np.mean(wcs.utils.proj_plane_pixel_scales(img_wcs) * u.degree).to('arcsec')\n",
    "    else:\n",
    "        pixelscale = pixscale\n",
    "        \n",
    "    return pixelscale.value\n",
    "\n",
    "def find_stars(img, fwhm=15., sigma_thresh=5.0):\n",
    "    \"\"\"\n",
    "        Uses DAOPhot implementations to detect sorces with a given FWHM and above a detection limit.\n",
    "        \n",
    "        Parameters:\n",
    "           img (numpy.ndarray): input image\n",
    "           fwhm (float, optional): expected FWHM for the sources (in pixels, default=15)\n",
    "           sigma_thresh (float, optional): detection limit (in sigmas, default=5.0)\n",
    "           \n",
    "        Returns:\n",
    "           table_detections (astropy.table.table.QTable): table of results containing the following columns:\n",
    "               ['id', 'xcentroid', 'ycentroid', 'sharpness', 'roundness1', 'roundness2', 'npix', 'sky', 'peak', 'flux', 'mag']\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    bkg, std_bkg = get_bkg(img)\n",
    "    \n",
    "    daofind = DAOStarFinder(fwhm=fwhm_sources, threshold=sigma_thresh * std_bkg)\n",
    "    \n",
    "    table_detections = daofind(img - bkg)    \n",
    "\n",
    "    print(\"A total of {} sources were detected above a {:.1f}-sigma threshold\".format(len(table_detections),sigma_thresh))\n",
    "    print(\"\")\n",
    "    \n",
    "    return table_detections\n",
    "\n",
    "\n",
    "def displ_table(table, format_cols='%.8g', max_rows=-1, max_cols=-1):\n",
    "    \"\"\"\n",
    "        Set basic definitions to print an Astropy Table on screen\n",
    "        \n",
    "        Parameters:\n",
    "           table (astropy.table.table.QTable): table to print\n",
    "           format_cols (str, optional): set formating for all tables for consistent output (default='%.8g')\n",
    "           max_rows (int, optional): maximum number of rows to print (default=-1, all)\n",
    "           max_cols (int, optional): maximum number of columns to print (default=-1, all)\n",
    "           \n",
    "        Returns:\n",
    "           print the table on screen, no variables to return.\n",
    "        \n",
    "    \"\"\"\n",
    "    for cols in table.colnames: table[cols].info.format = format_cols  # for consistent table output\n",
    "    # print entire table\n",
    "    print(table.pprint(max_lines=max_rows, max_width=max_cols))\n",
    "    \n",
    "def get_fwhm(img, table_sources, source_id=5, pixscale=10, stamp_radius=50, psf_model='moffat', fwhm_best_guess = 1.5, plot_results=False):\n",
    "    \"\"\"\n",
    "        Fit the FWHM of a point like source using a Gaussian or Moffat profile\n",
    "        \n",
    "        Parameters:\n",
    "           img (numpy.ndarray): input image\n",
    "           table_sources (astropy.table.table.QTable): table of sources from find_stars()\n",
    "           source_id (in, optional): id of the source to analyse (default=5)\n",
    "           pixscale (float): the pixel scale of the image (in arcseconds, default=10)\n",
    "           stamp_radius (int, optional): size of the grid to analyze the star (default=50)\n",
    "           psf_model (str, optional): 'moffat' or 'gaussian' model (default='moffat')\n",
    "           fwhm_best_guess (float, optional): if using a 'gaussian' profile. provide the best guess for the FWHM (in arcseconds)\n",
    "           plot_results (bool, optional): print out the results on screen\n",
    "           \n",
    "        Returns:\n",
    "           fwhm (astropy.units.quantity.Quantity): the FWHM of the point source (in arcseconds)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # select a bright (not saturated) source for PSF modelling:\n",
    "    isource = table_sources[source_id]\n",
    "\n",
    "    # High SN - 50\n",
    "    # Low SN - 33\n",
    "    # Non-uniform background - 78\n",
    "\n",
    "    if plot_results:\n",
    "        print (\"x pos: \" + str(isource['xcentroid']))\n",
    "        print (\"y pos: \" + str(isource['ycentroid']))\n",
    "\n",
    "    # show the source in a 100x100 region\n",
    "    if plot_results:\n",
    "        display(img[int(isource['ycentroid'] - stamp_radius):\n",
    "                    int(isource['ycentroid'] + stamp_radius), \n",
    "                    int(isource['xcentroid'] - stamp_radius): \n",
    "                    int(isource['xcentroid'] + stamp_radius)])\n",
    "        plt.show()\n",
    "    \n",
    "    median, std_bkg = get_bkg(img)\n",
    "\n",
    "    # Median bkg subtracted image\n",
    "    img_nobkg = img - median\n",
    "\n",
    "    # turn the 2D profile into a 1D distance array from the center of each pixel to the centroid of the source estimated by DAO Phot:\n",
    "    flux_counts = []\n",
    "    pixel_distance = []\n",
    "\n",
    "    x_cen = int(isource['xcentroid'])\n",
    "    y_cen = int(isource['ycentroid'])\n",
    "\n",
    "    # Pixels around detection loop\n",
    "    analysis_radius = int(np.round(0.33*stamp_radius))\n",
    "    for x in range(x_cen - analysis_radius, x_cen + analysis_radius):\n",
    "        for y in range(y_cen - analysis_radius, y_cen + analysis_radius):\n",
    "            flux_counts.append(((img_nobkg[y][x]) / isource['peak']))\n",
    "            pixel_distance.append(np.linalg.norm((isource['xcentroid'] - x, isource['ycentroid'] - y)))\n",
    "\n",
    "    if psf_model == 'gaussian':\n",
    "        # Fit the data using a Gaussian\n",
    "        model_init = models.Gaussian1D(amplitude=1.0, mean=0, stddev=fwhm_best_guess)\n",
    "    elif psf_model == 'moffat':\n",
    "        # Fit the data using a Moffat\n",
    "        model_init = models.Moffat1D(amplitude=1.0, x_0=0, gamma=2., alpha=3.5)\n",
    "    else:\n",
    "        raise Exception(\"Unknown model type: %s. Must be gaussian or moffat.\" % psf_model)\n",
    "\n",
    "    fitter     = fitting.SimplexLSQFitter()\n",
    "    fitted_psf = fitter(model_init, pixel_distance, flux_counts)\n",
    "\n",
    "    print (\"Fit value: {:.8g}\".format(fitter.fit_info['final_func_val']))\n",
    "    print (\"      SNR: {:.8g}\".format(np.sqrt(isource['flux'])))\n",
    "\n",
    "    # FHWM conversion\n",
    "    if psf_model == 'gaussian':\n",
    "        fwhm_fit = 2.355 * fitted_psf.stddev * pixscale\n",
    "    elif psf_model == 'moffat':\n",
    "        fwhm_fit = fitted_psf.gamma * 2 * np.sqrt(2 ** (1. / fitted_psf.alpha) - 1) * pixscale\n",
    "    else:\n",
    "        raise Exception(\"Unknown model type: %s. Must be gaussian or moffat.\" % psf_model)\n",
    "\n",
    "    print (\" Fit FWHM: {:.8g}\".format(fwhm_fit))\n",
    "\n",
    "    # Check fitting\n",
    "    color = 'green' if fitter.fit_info['final_func_val'] < 5.0 else 'red'\n",
    "\n",
    "    # Plot the data with the best-fit model\n",
    "    plt.figure()\n",
    "    plt.plot(pixel_distance, flux_counts, 'ko')\n",
    "    rx = np.linspace(0, int(max(pixel_distance)), int(max(pixel_distance)) * 10)\n",
    "    plt.plot(rx,\n",
    "             fitted_psf(rx),\n",
    "             color=color,\n",
    "             lw=3.0,\n",
    "             label='SNR: %.2f, Fit: %.2f, FWHM: %.2f\"' % (np.sqrt(isource['flux']),\n",
    "                                                          fitter.fit_info['final_func_val'],\n",
    "                                                          fwhm_fit))\n",
    "    plt.xlabel('Distance (pixels)')\n",
    "    plt.ylabel('Normalized flux (ADU)')\n",
    "    plt.title('%s profile fit' % psf_model)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return fwhm_fit\n",
    "    \n",
    "\n",
    "def get_bkg2d(img, bkg_box=34, filter_size=3, plot_results=False):\n",
    "    \"\"\"\n",
    "        Estimate a 2d background using an input fits image\n",
    "        \n",
    "        Parameters:\n",
    "           img (numpy.ndarray): input image\n",
    "           bkg_box (int, optional): The box size along each axis (default=34)\n",
    "           filter_size (int, optional): The window size of the 2D median filter to apply to the low-resolution background map. (default=3)\n",
    "           plot_results (bool, optional): print out the results on screen\n",
    "           \n",
    "        Returns:\n",
    "           fwhm (astropy.units.quantity.Quantity): the FWHM of the point source (in arcseconds)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    sigma_clip = SigmaClip(sigma=3., maxiters=10)\n",
    "    bkg_estimator = MedianBackground()\n",
    "    bkg = Background2D(img, (bkg_box, bkg_box), filter_size=(filter_size, filter_size),\n",
    "                       sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "    if plot_results:\n",
    "        display(bkg.background)\n",
    "        plt.show()\n",
    "\n",
    "    return bkg.background\n",
    "\n",
    "\n",
    "def do_phot(img, positions, bkg=None, gain=1., exptime=1., r_in=10, r_out=None):\n",
    "    \"\"\"\n",
    "        Perform aperture photometry on an input fits image\n",
    "        \n",
    "        Parameters:\n",
    "           img (numpy.ndarray): input image\n",
    "           positions (numpy.array): array of (x,y) values for extracting the photometry \n",
    "           bkg (numpy.ndarray, optional): input background estimate (default=None)\n",
    "           gain (float, optional): ratio of counts to the units of img to calculate the Poisson error of the sources.\n",
    "                                   If gain is zero, then the source Poisson noise component will not be included (default=1.)\n",
    "           exptime (float, optional): exposure time of the observations in seconds (default=1.)\n",
    "           r_in (float, optional): radius of the circle to measure the flux. (in pixels, default=10)\n",
    "           r_out (float, optional): the outer radius of the circular annulus (in pixels, default=None)\n",
    "           \n",
    "        Returns:\n",
    "           table_phot (astropy.table.table.QTable): table of results containing the following columns:\n",
    "               ['id', 'xcenter', 'ycenter', 'aperture_sum', 'aperture_error', 'annulus_sum', 'annulus_error',\n",
    "                'aperture_sum_nobkg', 'aperture_sum_nobkg_error', 'SNR']\n",
    "    \"\"\"\n",
    "    \n",
    "    if bkg is not None:\n",
    "        img_nobkg = img - bkg\n",
    "        # remove nan values from background\n",
    "        bkg[np.isnan(bkg)]=0.0\n",
    "        bkg_error = np.sqrt(abs(bkg))\n",
    "        phot_error = calc_total_error(img, bkg_error, gain)\n",
    "        \n",
    "        img = img_nobkg\n",
    "        #display(phot_error[0:800, 0:800])\n",
    "        #plt.show()\n",
    "    \n",
    "    # if no r_out is provided, perform simple aperture photometry\n",
    "    aper_in = CircularAperture(positions, r=r_in)\n",
    "    if r_out is not None: annulus_apertures = CircularAnnulus(positions, r_in=r_in, r_out=r_out)\n",
    "    \n",
    "    apertures = aper_in\n",
    "    if r_out is not None: apertures = [aper_in,annulus_apertures]\n",
    "    \n",
    "    if bkg is None:\n",
    "        table_phot = aperture_photometry(img, apertures)\n",
    "    else:\n",
    "        table_phot = aperture_photometry(img, apertures, error=phot_error)\n",
    "    \n",
    "    # remove background using the annulus\n",
    "    if r_out is not None: \n",
    "        table_phot.rename_column('aperture_sum_0', 'aperture_sum')\n",
    "        table_phot.rename_column('aperture_sum_1', 'annulus_sum')\n",
    "        table_phot.rename_column('aperture_sum_err_0', 'aperture_error')\n",
    "        table_phot.rename_column('aperture_sum_err_1', 'annulus_error')\n",
    "\n",
    "        # divide by exptime\n",
    "        #table_phot['aperture_sum'] /= exptime\n",
    "        #table_phot['annulus_sum'] /= exptime\n",
    "        #table_phot['aperture_error'] /= exptime\n",
    "        #table_phot['annulus_error'] /= exptime\n",
    "        \n",
    "        # Use the aperture_sum_1 to estimate the level of background around the source. We need to know the area of the annulus for this estimation:\n",
    "        bkg_mean = table_phot['annulus_sum'] / annulus_apertures.area\n",
    "        # Now remove the background estimation to all pixels in the aperture:\n",
    "        bkg_aper = bkg_mean * aper_in.area\n",
    "        flux_nobkg = table_phot['aperture_sum'] - bkg_aper\n",
    "        \n",
    "        \n",
    "        err_ap = table_phot['aperture_error']  / aper_in.area\n",
    "        err_an = table_phot['annulus_error']  / annulus_apertures.area\n",
    "        err_nobkg = np.sqrt(err_ap**2+err_an**2)*aper_in.area\n",
    "        \n",
    "        table_phot['aperture_sum_nobkg'] = flux_nobkg\n",
    "        table_phot['aperture_sum_nobkg_error'] = err_nobkg\n",
    "        #table_phot['aperture_sum_nobkg_error'] = table_phot['aperture_error']\n",
    "        table_phot['SNR'] = table_phot['aperture_sum_nobkg'] / table_phot['aperture_sum_nobkg_error']\n",
    "    else:\n",
    "        table_phot.rename_column('aperture_sum_err', 'aperture_error')\n",
    "        \n",
    "        # divide by exptime\n",
    "        table_phot['aperture_sum'] /= exptime\n",
    "        table_phot['aperture_error'] /= exptime\n",
    "        \n",
    "        table_phot['SNR'] = table_phot['aperture_sum'] / table_phot['aperture_error']\n",
    "        \n",
    "    # now plot\n",
    "    display(img[0:800, 0:800])\n",
    "    if r_out is not None: annulus_apertures.plot(color='purple', lw=2, alpha=1)\n",
    "    aper_in.plot(lw=2, ls=':', color='white')\n",
    "    plt.show()\n",
    "    \n",
    "    return table_phot\n",
    "\n",
    "\n",
    "def table_xy2sky(table, img_wcs, exptime=1., zp=25.):\n",
    "    \"\"\"\n",
    "        Read photometric table from do_phot() and converts (x,y) position and flux values to sky (RA,Dec) and magnitudes\n",
    "        \n",
    "        Parameters:\n",
    "           table (astropy.table.table.QTable): table from do_phot()\n",
    "           img_wcs (astropy.wcs.wcs.WCS): input WCS from the fits file\n",
    "           exptime (float, optional): exposure time of the observations in seconds (default=1.)\n",
    "           zp (float, optional): the photometric zero-point offset to be added to the instrumental magnitudes (default=25.)\n",
    "           \n",
    "        Returns:\n",
    "           table_out (astropy.table.table.QTable): table of results containing the following columns:\n",
    "               ['id', 'ra', 'dec', 'm', 'e_m', 'SNR']\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # prepare the output list\n",
    "    # convert (x,y) to (RA,Dec)\n",
    "    coords_xy = np.array([table['xcenter'], table['ycenter']]).T\n",
    "    coords_wcs = img_wcs.all_pix2world(coords_xy,0)\n",
    "    \n",
    "    table_out = table.copy()\n",
    "    table_out['ra'], table_out['dec'] = coords_wcs[:,0], coords_wcs[:,1]\n",
    "    \n",
    "    # if errors are provided, run:\n",
    "    if 'aperture_sum_nobkg_error' in table_out.colnames: \n",
    "        table_out['m'] = zp -2.5 * np.log10(table_phot['aperture_sum_nobkg']/exptime)\n",
    "        table_out['e_m'] = np.sqrt( ( ( 2.5 / np.log(10) ) * table_phot['aperture_sum_nobkg_error'] / table_phot['aperture_sum_nobkg'] )**2 )\n",
    "        table_out.remove_columns(['xcenter','ycenter','aperture_sum','aperture_error','annulus_sum','annulus_error','aperture_sum_nobkg','aperture_sum_nobkg_error'])\n",
    "\n",
    "    else:\n",
    "        table_out['m'] = zp -2.5 * np.log10(table_phot['aperture_sum']/exptime)\n",
    "        table_out['e_m'] = np.sqrt( ( ( 2.5 / np.log(10) ) * table_phot['aperture_error'] / table_phot['aperture_sum'] )**2 )\n",
    "        table_out.remove_columns(['xcenter','ycenter','aperture_sum','aperture_error'])\n",
    "\n",
    "    table_out = table_out['id','ra','dec','m','e_m','SNR']\n",
    "    return table_out\n",
    "    \n",
    "\n",
    "print('Packages loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "infolder = 'D:/SOAR/SAM/SO2022B-014/results/NGC121_A_2022-10-17/'\n",
    "\n",
    "filename = 'NGC121_A_B.fits'\n",
    "\n",
    "# remove '.fits' if existing\n",
    "filename = infolder+filename.rsplit('.fits', 1)[0]\n",
    "\n",
    "# open the fits file\n",
    "with fits.open(filename+'.fits') as hdu:\n",
    "    hdr = hdu[0].header\n",
    "    img = hdu[0].data\n",
    "    img_wcs = wcs.WCS(hdr)\n",
    "\n",
    "# replace Nan by zeros, if any\n",
    "img[np.isnan(img)] = 0\n",
    "\n",
    "# divide image by exposure time (ADU) -> (ADU/sec)\n",
    "#img /= hdr['EXPTIME']\n",
    "#cb_title='flux (ADU/sec)'\n",
    "\n",
    "display(img)\n",
    "plt.grid('on')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detections\n",
    "Using DAOPhot routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixscale = get_pixelscale(img_wcs)\n",
    "\n",
    "# Object detection\n",
    "fwhm_sources = ( 1.5 / pixscale ) # in pixels\n",
    "sigma_det = 3.0\n",
    "\n",
    "# run DAOFind to detect stars\n",
    "sources = find_stars(img, fwhm=fwhm_sources, sigma_thresh=sigma_det)\n",
    "\n",
    "displ_table(sources, max_rows=10)\n",
    "\n",
    "# show image with detections\n",
    "display(img)\n",
    "plt.scatter(sources['xcentroid'], sources['ycentroid'], s=200, alpha=0.5, facecolors='none', edgecolors='black')\n",
    "# display id's\n",
    "txt_id = sources['id']-1\n",
    "x = sources['xcentroid']\n",
    "y = sources['ycentroid']\n",
    "for i, txt in enumerate(txt_id):\n",
    "    plt.annotate(txt, (x[i], y[i]))\n",
    "plt.show()\n",
    "\n",
    "# get the FWHM of the PSF\n",
    "fwhm_psf = get_fwhm(img, sources, pixscale=pixscale, source_id=10, stamp_radius=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background modelling\n",
    "For non-uniform background, the constant median can be insuficient. \n",
    "\n",
    "Produce a 2D model of the background to be subtracted from the original image to improve the modelling of the stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background modelling\n",
    "bkg2d = get_bkg2d(img, bkg_box=34, plot_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aperture photometry\n",
    "# set the aperture radius as equivalent to the FWTM of a Gaussian with FWHM given by 'fwhm'\n",
    "#############################\n",
    "fwtm2fwhm = 4.29193/2.35482\n",
    "aperture_radius = ( fwhm_psf * fwtm2fwhm / pixscale ) # in pixels\n",
    "print('aperture_radius:', aperture_radius)\n",
    "\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "\n",
    "table_phot = do_phot(img, positions, bkg=bkg2d, gain=1., exptime=hdr['EXPTIME'], r_in=aperture_radius, r_out=1.5*aperture_radius)\n",
    "displ_table(table_phot, max_rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# converts from image to sky coordinates and magnitudes\n",
    "zp=25.0\n",
    "table_out = table_xy2sky(table_phot, img_wcs, exptime=hdr['EXPTIME'], zp=25.)\n",
    "\n",
    "displ_table(table_out,max_rows=10)\n",
    "\n",
    "df = table_out.to_pandas()\n",
    "df.to_csv(filename+'_aper_phot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
